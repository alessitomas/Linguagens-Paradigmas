{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMPILADORES-AULA 1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessitomas/Linguagens-Paradigmas/blob/main/COMPILADORES_AULA_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxHf3E81Qyz"
      },
      "source": [
        "**COMPILADORES - AULA 1**\n",
        "\n",
        "***Prof. Luciano Silva***\n",
        "\n",
        "**Objetivos da aula:**\n",
        "*   revisar os passos de compilação\n",
        "*   apresentar o conceito de analisador léxico\n",
        "*   implementar analisadores léxicos em Python, usando o módulo rply\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk9th_uMzOVk"
      },
      "source": [
        "**FASES DO PROCESSO DE COMPILAÇÃO**\n",
        "\n",
        "As diversas fases do processo de compilação são mostradas na imagem abaixo:\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Nuno-Oliveira-15/publication/266497079/figure/fig1/AS:295651775664128@1447500284302/Common-Compiler-Phases.png\"> <img>\n",
        "\n",
        "A partir de um programa-fonte (source), a primeira fase do processo de compilação é a quebra do programa em **tokens**, realizado através do **analisador léxico**.\n",
        "\n",
        "Uma vez identificados os tokens, o compilador precisa verificar se eles aparecem numa ordem determinada por uma **gramática**, processo que é realizado pelo **analisador sintático**. O produto do analisador sintático é a chamada **árvore de análise sintática** ou, abreviadamente, **árvore sintática**.\n",
        "\n",
        "A partir da árvore sintática, o compilador utiliza o **analisador semântico**. Este analisador percorre a árvore sintática para verificar, por exemplo, se há algum erro de tipo, se as funções são chamada com os argumentos corretos, dentre outras verificações.\n",
        "\n",
        "Uma vez que o programa não tenha erros sintáticos e semânticos, o compilador começa as tarefas de geração de código. O **gerador de código intermediário** é o primeiro deles e, para este gerador, a máquina-alvo do código é considerada como tendo um número infinito de registradores. Isto facilita bastante a geração de código inicial.\n",
        "\n",
        "A partir deste código intermediário, caímos em um problema de otimização: como transformar um código com infinitos registradores em um código que utilize um número finito de registradores. Esta é uma das tarefas do **otimizador de código**.\n",
        "\n",
        "Finalmente, uma vez otimizado o código, podemos gerar o código final para a máquina-alvo utilizando o **gerador de código**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUepNFu-4Onu"
      },
      "source": [
        "**ANALISADOR LÉXICO**\n",
        "\n",
        "O **analisador léxico** é um módulo de compilador responsável por quebrar o programa a ser compilado em **tokens**. Um token é, essencilamente, uma 2-upla (valor,tipo). Por exemplo, o token (123,NUMBER) diz que a entrada 123 reconhecida é um número.\n",
        "\n",
        "A representação operacional de um analisador léxico é, essencialmente, um **autômato (de estados) finito**. Abaixo temos um exemplo de um analisador léxico para reconhecer números inteiros sem sinal.\n",
        "\n",
        "<img src=\"https://www.csee.umbc.edu/courses/undergraduate/CMSC331/fall17/park/homeworks/hw3/dfa.gif\"> <img>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGMxqj9y7vWS"
      },
      "source": [
        "**EXERCÍCIO RESOLVIDO**\n",
        "\n",
        "Queremos constuir um analisador léxico para os símbolos terminais da gramática abaixo:\n",
        "\n",
        "\\<expression\\> ::= NUMBER\n",
        "\n",
        "               | \\<expression\\> \"+\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"-\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"*\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"/\" \\<expression\\>\n",
        "\n",
        "               | \"(\" <expression> \")\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdlT1XbX8PFb"
      },
      "source": [
        "O primeiro passo é instalar o rply, um módulo para construir analisadores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbWUx55j1tLM",
        "outputId": "918a89d0-7cbc-4756-9a49-92038b0484f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rply"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rply\n",
            "  Downloading rply-0.7.8-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from rply) (1.4.4)\n",
            "Installing collected packages: rply\n",
            "Successfully installed rply-0.7.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQEvnI9-9S-n"
      },
      "source": [
        "Toda a documentação do rply pode ser encontrada abaixo:\n",
        "\n",
        "<a href=\"https://rply.readthedocs.io/en/latest/\">Documentação RPLY </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdp5ClkZ98Tw"
      },
      "source": [
        "O segundo passo é construir o analisador léxico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rezf3OAt1P7_"
      },
      "source": [
        "from rply import LexerGenerator\n",
        "\n",
        "lg = LexerGenerator()\n",
        "# lg.add('NUMBER', r'\\d+')\n",
        "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
        "lg.add('EQUALS',r'\\=')\n",
        "lg.add('DELIM',r'\\;')\n",
        "lg.add('NUMBER', r'(\\+|-)?\\d+\\.?(\\d+)')\n",
        "lg.add('PLUS', r'\\+')\n",
        "lg.add('MINUS', r'\\-')\n",
        "lg.add('MUL', r'\\*')\n",
        "lg.add('DIV', r'\\/')\n",
        "lg.add('OPEN_PARENS', r'\\(')\n",
        "lg.add('CLOSE_PARENS', r'\\)')\n",
        "\n",
        "lg.ignore('\\s+')\n",
        "\n",
        "lexer = lg.build()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxpqmaf9khR"
      },
      "source": [
        "Observe que, associado a cada classe léxica, temos uma expressão regular associada. Esta expressão regular usa a facilidade RegEx do Python, cuja documentação pode ser enontrada abaixo:\n",
        "\n",
        "<a href=\"https://blog.geekhunter.com.br/python-regex/\"> Expressões Regulares em Python </a>\n",
        "\n",
        "Para usar somente o analisador léxico, podemos usar o código abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CrRKNZi9vMr",
        "outputId": "818a31b8-8090-482a-b258-5f70fb07987a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in lexer.lex('1.6+1.8-1.573907503'):\n",
        "  print(token)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token('NUMBER', '1.6')\n",
            "Token('NUMBER', '+1.8')\n",
            "Token('NUMBER', '-1.573907503')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PduMxWsU_Vy7"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Modifique o analisador léxico para reconhecer números inteiros com ou sem  sinal. Por exemplo: +6, -58, 100.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMh74pg_okJ"
      },
      "source": [
        "#digite sua solução aqui\n",
        "lg.add('NUMBER', r'+-?\\d+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2YCDTUv_yJT"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Modifique o analisador léxico para reconhecer números em ponto flutuante com ou sem  sinal. Por exemplo: +6.56, -6.089678, 234.475."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OohbNOEg_90x"
      },
      "source": [
        "\n",
        "#digite sua solução aqui\n",
        "lg.add('NUMBER', r'(\\+|-)?\\d+\\.?(\\d+)')\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKWWWx3aAK30"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Considere a nossa gramática inicial com a modificação abaixo. Nesta alteração, id é o nome de uma variável que começa com letra (minúscula ou maiúscula) e, depois disto, pode conter letras ou números. Implemente e teste um analisador  léxico para esta alteração.\n",
        "\n",
        "\\<atribuicao\\> ::= **id** **\"=\"** \\<expression\\> **\";\"**\n",
        "\n",
        "\\<expression\\> ::= **NUMBER**\n",
        "\n",
        "               | \\<expression\\> \"+\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"-\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"*\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"/\"\\<expression\\>\n",
        "\n",
        "               | \"(\" <expression> \")\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5twoUAaCDr9"
      },
      "source": [
        "#digite sua solução aqui\n",
        "\n",
        "lg = LexerGenerator()\n",
        "#digite sua solução aqui\n",
        "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
        "\n",
        "lg.ignore('\\s+')\n",
        "\n",
        "lexer = lg.build()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in lexer.lex('a'):\n",
        "  print(token)"
      ],
      "metadata": {
        "id": "bDBFgoSPEs76",
        "outputId": "86c008f8-5128-4458-fdf1-02da45caca59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token('ID', 'a')\n"
          ]
        }
      ]
    }
  ]
}